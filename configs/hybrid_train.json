{
    "backbone": "transformer",
    "encoder": "tiny07",
    "model_name": "hybrid_cnn_transformer",
    "data_path": "c:\\code\\LINGMI-MR\\data\\blender_colon",
    "val_path": null,
    "log_dir": "./hybrid_logs",
    "num_epochs": 50,
    "log_frequency": 1,
    "save_frequency": 1,
    "png": true,
    "learning_rate": 0.0001,
    "lr_decade_coeff": 0.9,
    "betas": [0.9, 0.999],
    "weight_decay": 0.01,

    "num_layers": 18,
    "height": 320,
    "width": 320,
    "frame_ids": [0],
    "scales": [0],

    "batch_size": 16,
    "num_workers": 2,

    "use_depth_loss": true,
    "use_smooth_loss": true,
    "use_normal_loss": true,

    "weight_depth_loss": 1.0,
    "weight_smooth_loss": 0.5,
    "weight_normal_pc_loss": 0.25,
    "weight_normal_norm_loss": 0.25,

    "test": false,
    
    "description": {
        "architecture": "Hybrid CNN-Transformer",
        "encoder": "Swin Transformer Tiny (window size 7x7)",
        "decoder": "CNN-based Depth Decoder",
        "features": [
            "Multi-scale supervision (4 scales: 0,1,2,3)",
            "Swin Transformer for global context",
            "CNN decoder for spatial details",
            "Geometry-aware losses (depth + smooth + normal)",
            "Window attention mechanism (7x7)"
        ],
        "differences_from_resnet18": [
            "Transformer encoder vs ResNet18 CNN",
            "Self-attention for long-range dependencies",
            "Multi-scale outputs with weighted losses",
            "Normal loss enabled for 3D geometry",
            "Lower learning rate (0.0001 vs 0.01)",
            "Smaller batch size (8 vs 16) due to memory"
        ],
        "paper_alignment": "Hybrid CNN + Transformer for Endoscopy 3D Reconstruction"
    }
}
